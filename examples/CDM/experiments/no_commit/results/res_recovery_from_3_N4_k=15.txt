PRISM
=====

Version: 4.0.1.games
Date: Sat Oct 08 17:23:07 BST 2011
Hostname: qavbench.comlab
Command line: prism -ex examples/games/CDM/experiments/no_commit/cdm4032.smg examples/games/CDM/experiments/no_commit/props_recovery_from_3_N4.pctl -const 'Pexp=0.5,Q1=1.0,Q2=0.5,Q3=0.25,gamma=2.0,eta=1.0,lambda=1.0,k=15'

Parsing model file "examples/games/CDM/experiments/no_commit/cdm4032.smg"...

Parsing properties file "examples/games/CDM/experiments/no_commit/props_recovery_from_3_N4.pctl"...

8 properties:
(1) filter(range, <<[1]>> Pmax=? [ F<=k ((sched=1)&(<<[1]>> P>0.9 [ F<=10 all_prefer_1 ])) ], all_prefer_3&sched=0)
(2) filter(range, <<[1, 2]>> Pmax=? [ F<=k ((sched=1|sched=2)&(<<[1, 2]>> P>0.9 [ F<=10 all_prefer_1 ])) ], all_prefer_3&sched=0)
(3) filter(range, <<[1, 2, 3]>> Pmax=? [ F<=k ((sched=1|sched=2|sched=3)&(<<[1, 2, 3]>> P>0.9 [ F<=10 all_prefer_1 ])) ], all_prefer_3&sched=0)
(4) filter(range, <<[1, 2, 3, 4]>> Pmax=? [ F<=k ((sched=1|sched=2|sched=3|sched=4)&(<<[1, 2, 3, 4]>> P>0.9 [ F<=10 all_prefer_1 ])) ], all_prefer_3&sched=0)
(5) filter(range, <<[1]>> Pmax=? [ F<=k ((sched=1)&(<<[1]>> R{"ntot1"}<10 [ F all_prefer_1 ])) ], all_prefer_3&sched=0)
(6) filter(range, <<[1, 2]>> Pmax=? [ F<=k ((sched=1|sched=2)&(<<[1, 2]>> R{"ntot12"}<20 [ F all_prefer_1 ])) ], all_prefer_3&sched=0)
(7) filter(range, <<[1, 2, 3]>> Pmax=? [ F<=k ((sched=1|sched=2|sched=3)&(<<[1, 2, 3]>> R{"ntot123"}<30 [ F all_prefer_1 ])) ], all_prefer_3&sched=0)
(8) filter(range, <<[1, 2, 3, 4]>> Pmax=? [ F<=k ((sched=1|sched=2|sched=3|sched=4)&(<<[1, 2, 3, 4]>> R{"ntot1234"}<40 [ F all_prefer_1 ])) ], all_prefer_3&sched=0)

Model constants: Pexp=0.5,eta=1,gamma=2,lambda=1,Q1=1,Q2=0.5,Q3=0.25,k=15

-------------------------------------------

Building model...

Computing reachable states...
 11645
Reachable states exploration and model construction done in 0.758 secs.
Sorting reachable states list...

Time for model construction: 0.841 seconds.

Type:        SMG

States:      11645 (1 initial)
Transitions: 83252
Choices:     29025
Max/avg:     3/2.49

-------------------------------------------

Model checking: filter(range, <<[1]>> Pmax=? [ F<=k ((sched=1)&(<<[1]>> P>0.9 [ F<=10 all_prefer_1 ])) ], all_prefer_3&sched=0)
Model constants: Pexp=0.5,eta=1,gamma=2,lambda=1,Q1=1,Q2=0.5,Q3=0.25,k=15

States satisfying filter all_prefer_3&sched=0: 16

Range of values over states satisfying filter: [5.817630882156817E-4,0.001111099799388494]

Time for model checking: 0.286 seconds.

Result: [5.817630882156817E-4,0.001111099799388494] (range of values over states satisfying filter)

-------------------------------------------

Model checking: filter(range, <<[1, 2]>> Pmax=? [ F<=k ((sched=1|sched=2)&(<<[1, 2]>> P>0.9 [ F<=10 all_prefer_1 ])) ], all_prefer_3&sched=0)
Model constants: Pexp=0.5,eta=1,gamma=2,lambda=1,Q1=1,Q2=0.5,Q3=0.25,k=15

States satisfying filter all_prefer_3&sched=0: 16

Range of values over states satisfying filter: [0.008253540074902433,0.016942932085548076]

Time for model checking: 0.215 seconds.

Result: [0.008253540074902433,0.016942932085548076] (range of values over states satisfying filter)

-------------------------------------------

Model checking: filter(range, <<[1, 2, 3]>> Pmax=? [ F<=k ((sched=1|sched=2|sched=3)&(<<[1, 2, 3]>> P>0.9 [ F<=10 all_prefer_1 ])) ], all_prefer_3&sched=0)
Model constants: Pexp=0.5,eta=1,gamma=2,lambda=1,Q1=1,Q2=0.5,Q3=0.25,k=15

States satisfying filter all_prefer_3&sched=0: 16

Range of values over states satisfying filter: [0.04193810133173095,0.08306873152993555]

Time for model checking: 0.216 seconds.

Result: [0.04193810133173095,0.08306873152993555] (range of values over states satisfying filter)

-------------------------------------------

Model checking: filter(range, <<[1, 2, 3, 4]>> Pmax=? [ F<=k ((sched=1|sched=2|sched=3|sched=4)&(<<[1, 2, 3, 4]>> P>0.9 [ F<=10 all_prefer_1 ])) ], all_prefer_3&sched=0)
Model constants: Pexp=0.5,eta=1,gamma=2,lambda=1,Q1=1,Q2=0.5,Q3=0.25,k=15

States satisfying filter all_prefer_3&sched=0: 16

Range of values over states satisfying filter: [0.13058438990104967,0.23972604153396668]

Time for model checking: 0.24 seconds.

Result: [0.13058438990104967,0.23972604153396668] (range of values over states satisfying filter)

-------------------------------------------

Model checking: filter(range, <<[1]>> Pmax=? [ F<=k ((sched=1)&(<<[1]>> R{"ntot1"}<10 [ F all_prefer_1 ])) ], all_prefer_3&sched=0)
Model constants: Pexp=0.5,eta=1,gamma=2,lambda=1,Q1=1,Q2=0.5,Q3=0.25,k=15
Building reward structure...

States satisfying filter all_prefer_3&sched=0: 16

Range of values over states satisfying filter: [0.05485696198823167,0.0888522725649061]

Time for model checking: 3.845 seconds.

Result: [0.05485696198823167,0.0888522725649061] (range of values over states satisfying filter)

-------------------------------------------

Model checking: filter(range, <<[1, 2]>> Pmax=? [ F<=k ((sched=1|sched=2)&(<<[1, 2]>> R{"ntot12"}<20 [ F all_prefer_1 ])) ], all_prefer_3&sched=0)
Model constants: Pexp=0.5,eta=1,gamma=2,lambda=1,Q1=1,Q2=0.5,Q3=0.25,k=15
Building reward structure...

States satisfying filter all_prefer_3&sched=0: 16

Range of values over states satisfying filter: [0.19711884946665303,0.24609894231996243]

Time for model checking: 6.215 seconds.

Result: [0.19711884946665303,0.24609894231996243] (range of values over states satisfying filter)

-------------------------------------------

Model checking: filter(range, <<[1, 2, 3]>> Pmax=? [ F<=k ((sched=1|sched=2|sched=3)&(<<[1, 2, 3]>> R{"ntot123"}<30 [ F all_prefer_1 ])) ], all_prefer_3&sched=0)
Model constants: Pexp=0.5,eta=1,gamma=2,lambda=1,Q1=1,Q2=0.5,Q3=0.25,k=15
Building reward structure...

States satisfying filter all_prefer_3&sched=0: 16

Range of values over states satisfying filter: [0.052395557235519544,0.14767915176997376]

Time for model checking: 17.778 seconds.

Result: [0.052395557235519544,0.14767915176997376] (range of values over states satisfying filter)

-------------------------------------------

Model checking: filter(range, <<[1, 2, 3, 4]>> Pmax=? [ F<=k ((sched=1|sched=2|sched=3|sched=4)&(<<[1, 2, 3, 4]>> R{"ntot1234"}<40 [ F all_prefer_1 ])) ], all_prefer_3&sched=0)
Model constants: Pexp=0.5,eta=1,gamma=2,lambda=1,Q1=1,Q2=0.5,Q3=0.25,k=15
Building reward structure...

States satisfying filter all_prefer_3&sched=0: 16

Range of values over states satisfying filter: [0.13058438990104967,0.23972604153396668]

Time for model checking: 0.171 seconds.

Result: [0.13058438990104967,0.23972604153396668] (range of values over states satisfying filter)

