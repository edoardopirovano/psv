PRISM
=====

Version: 4.0.1.games
Date: Thu Oct 06 16:55:30 BST 2011
Hostname: qavbench.comlab
Command line: prism -ex examples/games/CDM/experiments/no_commit/cdm5032.smg examples/games/CDM/experiments/no_commit/props_total_5.pctl -const 'Pexp=0.5,Q1=1.0,Q2=0.5,Q3=0.25,gamma=2.5,eta=1.0,lambda=1.0'

Parsing model file "examples/games/CDM/experiments/no_commit/cdm5032.smg"...

Parsing properties file "examples/games/CDM/experiments/no_commit/props_total_5.pctl"...

10 properties:
(1) <<[0, 1]>> R{"ntot12345"}min=? [ F all_prefer_1 ]
(2) <<[0, 1, 2]>> R{"ntot12345"}min=? [ F all_prefer_1 ]
(3) <<[0, 1, 2, 3]>> R{"ntot12345"}min=? [ F all_prefer_1 ]
(4) <<[0, 1, 2, 3, 4]>> R{"ntot12345"}min=? [ F all_prefer_1 ]
(5) <<[0, 1, 2, 3, 4, 5]>> R{"ntot12345"}min=? [ F all_prefer_1 ]
(6) <<[0, 1]>> R{"ntot1"}min=? [ F all_prefer_1 ]
(7) <<[0, 1, 2]>> R{"ntot12"}min=? [ F all_prefer_1 ]
(8) <<[0, 1, 2, 3]>> R{"ntot123"}min=? [ F all_prefer_1 ]
(9) <<[0, 1, 2, 3, 4]>> R{"ntot1234"}min=? [ F all_prefer_1 ]
(10) <<[0, 1, 2, 3, 4, 5]>> R{"ntot12345"}min=? [ F all_prefer_1 ]

Model constants: Pexp=0.5,eta=1,gamma=2.5,lambda=1,Q1=1,Q2=0.5,Q3=0.25

-------------------------------------------

Building model...

Computing reachable states...
 97654 100032
Reachable states exploration and model construction done in 3.118 secs.
Sorting reachable states list...

Time for model construction: 3.334 seconds.

Type:        SMG

States:      100032 (1 initial)
Transitions: 843775
Choices:     255092
Max/avg:     3/2.55

-------------------------------------------

Model checking: <<[0, 1]>> R{"ntot12345"}min=? [ F all_prefer_1 ]
Model constants: Pexp=0.5,eta=1,gamma=2.5,lambda=1,Q1=1,Q2=0.5,Q3=0.25
Building reward structure...

Value in the initial state: 1194.7667046999504

Time for model checking: 252.068 seconds.

Result: 1194.7667046999504 (value in the initial state)

-------------------------------------------

Model checking: <<[0, 1, 2]>> R{"ntot12345"}min=? [ F all_prefer_1 ]
Model constants: Pexp=0.5,eta=1,gamma=2.5,lambda=1,Q1=1,Q2=0.5,Q3=0.25
Building reward structure...

Value in the initial state: 332.3925287971755

Time for model checking: 74.448 seconds.

Result: 332.3925287971755 (value in the initial state)

-------------------------------------------

Model checking: <<[0, 1, 2, 3]>> R{"ntot12345"}min=? [ F all_prefer_1 ]
Model constants: Pexp=0.5,eta=1,gamma=2.5,lambda=1,Q1=1,Q2=0.5,Q3=0.25
Building reward structure...

Value in the initial state: 181.11240883763958

Time for model checking: 45.15 seconds.

Result: 181.11240883763958 (value in the initial state)

-------------------------------------------

Model checking: <<[0, 1, 2, 3, 4]>> R{"ntot12345"}min=? [ F all_prefer_1 ]
Model constants: Pexp=0.5,eta=1,gamma=2.5,lambda=1,Q1=1,Q2=0.5,Q3=0.25
Building reward structure...

Value in the initial state: 100.00408410613818

Time for model checking: 58.293 seconds.

Result: 100.00408410613818 (value in the initial state)

-------------------------------------------

Model checking: <<[0, 1, 2, 3, 4, 5]>> R{"ntot12345"}min=? [ F all_prefer_1 ]
Model constants: Pexp=0.5,eta=1,gamma=2.5,lambda=1,Q1=1,Q2=0.5,Q3=0.25
Building reward structure...

Value in the initial state: 17.500589767249977

Time for model checking: 47.699 seconds.

Result: 17.500589767249977 (value in the initial state)

-------------------------------------------

Model checking: <<[0, 1]>> R{"ntot1"}min=? [ F all_prefer_1 ]
Model constants: Pexp=0.5,eta=1,gamma=2.5,lambda=1,Q1=1,Q2=0.5,Q3=0.25
Building reward structure...

Value in the initial state: 336.6309603753763

Time for model checking: 354.353 seconds.

Result: 336.6309603753763 (value in the initial state)

-------------------------------------------

Model checking: <<[0, 1, 2]>> R{"ntot12"}min=? [ F all_prefer_1 ]
Model constants: Pexp=0.5,eta=1,gamma=2.5,lambda=1,Q1=1,Q2=0.5,Q3=0.25
Building reward structure...

Value in the initial state: 172.9564036383009

Time for model checking: 124.823 seconds.

Result: 172.9564036383009 (value in the initial state)

-------------------------------------------

Model checking: <<[0, 1, 2, 3]>> R{"ntot123"}min=? [ F all_prefer_1 ]
Model constants: Pexp=0.5,eta=1,gamma=2.5,lambda=1,Q1=1,Q2=0.5,Q3=0.25
Building reward structure...

Value in the initial state: 120.95160635930799

Time for model checking: 86.823 seconds.

Result: 120.95160635930799 (value in the initial state)

-------------------------------------------

Model checking: <<[0, 1, 2, 3, 4]>> R{"ntot1234"}min=? [ F all_prefer_1 ]
Model constants: Pexp=0.5,eta=1,gamma=2.5,lambda=1,Q1=1,Q2=0.5,Q3=0.25
Building reward structure...

Value in the initial state: 77.48130891215912

Time for model checking: 66.801 seconds.

Result: 77.48130891215912 (value in the initial state)

-------------------------------------------

Model checking: <<[0, 1, 2, 3, 4, 5]>> R{"ntot12345"}min=? [ F all_prefer_1 ]
Model constants: Pexp=0.5,eta=1,gamma=2.5,lambda=1,Q1=1,Q2=0.5,Q3=0.25
Building reward structure...

Value in the initial state: 17.500589767249977

Time for model checking: 53.887 seconds.

Result: 17.500589767249977 (value in the initial state)

